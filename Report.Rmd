---
title: "Evaluating the Impact of Baseline Hazard Function Misspecification on Treatment Effect Estimation"
author: "Charly Fowler, Hanfei Qi, Robert Tumasian III , and Haoyang Yi"
date: "February 24, 2021"
output: pdf_document
---

```{r, include=FALSE}
library(tidyverse)
library(png)
library(survival)
library(quantreg)
library(glmnet)
library(MASS)
library(pROC)
library(simsurv)
library(flexsurv)
library(broom)
knitr::opts_chunk$set(echo = TRUE)
```

# Objectives

The goal of this study is to evaluate how misspecifying the baseline hazard function can influence the estimation of treatment effects in survival without censored observations. This work focuses on conducting simulations to compare the exponential and Weibull proportional hazards models to the Cox proportional hazards model. We also discuss the impact of utilizing an overly complicated model (e.g., Cox) when a less complex model (e.g., exponential) is sufficient.

# Statistical Methods

Survival analysis is used to analyze time-to-event data (e.g., time to symptom onset or time to mortality). Survival functions, $S(t)$, measure the probability of an individual not experiencing an event beyond a certain time $t$. Similarly, hazard functions, $h(t)$, measure the instantaneous risk of failure at a certain time $t$, given that the individual has not experienced an event until that time. The hazard function can be expressed as $\frac{f(t)}{S(t)}$, where $f(t)$ is the distribution of survival times.\par

One purpose of proportional hazards modeling is to assess the effectiveness of a particular treatment ($X$) over survival time $T$, where the hazard ratio for patient $i$ at time $t$ is defined as $h_i(t)=h_0(t)e^{x_i\beta}$. Here, $h_0(t)$ denotes the pre-specified baseline hazard function, $x_i$ indicates treatment allocation (0=control, 1=treatment), and $\beta$ represents the log hazard ratio, or the hazard reduction among treated individuals compared to the control group. Thus, the proportional hazard can be expressed as $\frac{h(t|x_0)}{h(t|x_1)}=e^{\beta(x_0-x_1)}$, which is independent of survival time $t$.\par

We consider three proportional hazards models (exponential, Weibull, and Cox). The exponential and Weibull models  implement their respective baseline hazard functions, while the Cox model estimates $\beta$ without this specification. It is important to mention that even if the baseline hazard function is known, the Cox model is still expected to perform well due to its semi-parametric efficiency (Anderson et al, 1982). All three models impose the restraint that the effect of the treatment be multiplicative on the hazard curve. The baseline hazard curves we consider are shown in Figure 1 below.\par

# Simulation Design

All simulation data was generated using the `simsurv` function in the `simsurv` package. We defined a binomial treatment variable (`trt`) with $p=0.5$ to ensure equal likelihood of random assignment to the treatment or control group. The resulting dataset contains time of event (`eventtime`), status (`status`), and treatment group (`trt`). Since we did not simulate censored observations, the `eventtime` variable represents time of event for all subjects (complete data available for all subjects; no missingness due to dropout or event occurrence).\par

We simulated survival data from six different baseline hazard distributions, using $\beta = -0.5$ as the true treatment effect size. First, we simulated from an exponential distribution with $\lambda = 0.1$, and then from a Weibull distribution with $\lambda = 0.1$ and $\gamma=0.5,2,5$. Note that when $\gamma=1$, the exponential and Weibull distributions are equivalent. These baseline hazards were chosen to consider monotone decreasing ($\gamma=0.5$), constant (exponential), and monotone increasing ($\gamma=2,5$) baseline hazard curves. Next, we simulated from lognormal ($\mu=0,\sigma=0.5$) and piecewise distributions (inspired by Brilleman et al.) to consider non-monotone baseline hazard functions and to better understand the implications of misspecifying the underlying distribution of survival times when fitting a model. All continuous baseline hazard functions are provided in Table 1 below, and baseline hazard functions are plotted beneath in Figure 1.\par

\bigskip


$$
\begin{array} {lccc}
\hline \text {} & \text { Exponential } & \text { Weibull } & \text { Lognormal } \\
\hline
\text { $h_0(t)$ } & \lambda & \lambda\gamma t^{\gamma-1} & \frac{\frac{1}{t \sigma} \phi(\frac{ln(t)}{\sigma})}{\Phi(\frac{-ln(t)}{\sigma})} \\
\hline
\end{array}
$$

\small Table 1. Continuous baseline hazard functions, $h_0(t)$, considered in this study. The normal PDF and CDF are denoted by $\phi$ and $\Phi$, respectively.


\bigskip


\bigskip

```{r, echo= F, warning = F,out.width="70%",fig.align='center'}
#plot hazards: 

set.seed(1729)
ncuts <- 19
cuts <- sort(rexp(ncuts, rate = 0.1))
pw_times <- c(0, cuts)
N <- length(pw_times)
pw_haz <- sort(abs(rnorm(N)))
pw_haz <- abs(pw_haz - median(pw_haz))

haz_piece <- function(t, ...) {
   pw_haz[findInterval(t, pw_times)]
}

haz_log <- function(t) {
  ((1/t*0.5)*dnorm(log(t)/0.5,mean=-0,sd=0.5))/
    (pnorm(-log(t)/0.5,mean=0,sd=0.5))
}

haz_weibull_0.5 = function(t){
  0.5 * t^(0.5-1)
}

haz_exponential = function(t){
  1 * t^(1-1)
}

p <- ggplot(data = data.frame(x = 0), mapping = aes(x = x))

p + 
  stat_function(fun = haz_piece, aes(color = "piece-wise")) + 
  stat_function(fun = haz_log, aes(col = "log-normal")) + 
  stat_function(fun = haz_weibull_0.5, aes(col = "weibull (gamma = 0.5)")) + 
  stat_function(fun = haz_exponential, aes(col = "pink")) + 
  xlim(0,20) + 
  ylim(0,2) + 
  theme_minimal() + 
  scale_color_manual(name = "Hazard Functions", 
                     values = c("red", "green", "blue", "orange"), 
                     labels = c("Lognormal", "Piecewise", "Exponential", "Weibull (gamma = 0.5)" )) + 
  theme(legend.position="bottom") + 
  labs(x = "t", y = "Hazard")
  
```

\small Figure 1. Baseline hazard functions used in this study for data generation. The lognormal distribution uses $\mu=0$ and $\sigma=0.5$. The piecewise distribution is based on curve generated by Brilleman et al. The Weibull distributions with $\gamma = 2,5$ have been omitted due to scaling (very steep growth).

\bigskip

Altogether, 1000 survival datasets containing 100 samples were simulated for each baseline hazard function. Each dataset was used to fit all three proportional hazards models and extract the estimated treatment effects ($\beta$). Furthermore, we generated six additional datasets of 100 samples for each baseline hazard function and fit exponential, Weibull, and Cox models for visualization in Figure 2.

# Results
To assess model performance, we plotted the survival probability versus time for all three models with a sample from each of the six simulation schemes (Figure 2). We also used mean-squared error (MSE) and the mean and variance of the estimated treatment effect among all 1000 simulations to evaluate model performance (Tables 2 and 3).

```{r,include=FALSE}
################# Generate Exp or Weib dist data ###################
cov <- data.frame(id = 1:500,
                    trt = rbinom(500, 1, 0.5))
  
# Simulate the event times

dat.weib0.5 <- simsurv(lambdas = 0.1, 
               gammas = 0.5, #change gamma,or use lognormal simulation
               betas = c(trt = -0.5), 
               x = cov)

dat.weib0.5 <- merge(cov, dat.weib0.5)


dat.exp <- simsurv(lambdas = 0.1, 
               gammas = 1, #change gamma,or use lognormal simulation
               betas = c(trt = -0.5), 
               x = cov)

dat.exp <- merge(cov, dat.exp)

dat.weib2 <- simsurv(lambdas = 0.1, 
               gammas = 2, #change gamma,or use lognormal simulation
               betas = c(trt = -0.5), 
               x = cov)

dat.weib2 <- merge(cov, dat.weib2)

dat.weib5 <- simsurv(lambdas = 0.1, 
               gammas = 5, #change gamma,or use lognormal simulation
               betas = c(trt = -0.5), 
               x = cov)

dat.weib5 <- merge(cov, dat.weib5)


################### Generate lognormal dist data ###################
# log-norm hazard fn
haz <- function(t, x, betas, mu, sigma) {
  exp(betas * (x)) * ((1/t*sigma)*dnorm(log(t)/sigma,mean=mu,sd=sigma))/
    (pnorm(-log(t)/sigma,mean=mu,sd=sigma))
}
# sim log-norm data
cov <- data.frame(trt = rbinom(100, 1, 0.5))
dat.lognorm <- cbind(simsurv(hazard = haz, 
                 x = cov,
                 mu = 0, 
                 sigma = 0.5,
                 betas = c(trt = -0.5)), 
                 cov)
  

################### Generate piece-wise dist data ###################
set.seed(1729)
ncuts <- 19
cuts <- sort(rexp(ncuts, rate = 0.1))
pw_times <- c(0, cuts)
N <- length(pw_times)
pw_haz <- sort(abs(rnorm(N)))
pw_haz <- abs(pw_haz - median(pw_haz))

haz <- function(t, x, betas, lb_interval, haz_interval, ...) {
  exp(betas * (x)) * haz_interval[findInterval(t, lb_interval)]
}

cov <- data.frame(trt = rbinom(100, 1, 0.5))
dat.piecewise <- cbind(simsurv(hazard = haz, 
                 x = cov,
                 lb_interval = pw_times, 
                 haz_interval = pw_haz, 
                 betas = c(trt = -0.5)), 
               cov)

# Merge the simulated event times onto covariate data frame
# No parameters need to be changed
s.weib0.5 <- with(dat.weib0.5,Surv(eventtime,status))
s.exp <- with(dat.exp,Surv(eventtime,status))
s.weib2 <- with(dat.weib2,Surv(eventtime,status))
s.weib5 <- with(dat.weib5,Surv(eventtime,status))
s.lognorm <- with(dat.lognorm,Surv(eventtime,status))
s.piecewise <- with(dat.piecewise,Surv(eventtime,status))

sExp1 <- survreg(s.weib0.5 ~ as.factor(trt),dist='exp',data=dat.weib0.5)
sExp2 <- survreg(s.exp ~ as.factor(trt),dist='exp',data=dat.exp)
sExp3 <- survreg(s.weib2 ~ as.factor(trt),dist='exp',data=dat.weib2)
sExp4 <- survreg(s.weib5 ~ as.factor(trt),dist='exp',data=dat.weib5)
sExp5 <- survreg(s.lognorm ~ as.factor(trt),dist='exp',data=dat.lognorm)
sExp6 <- survreg(s.piecewise ~ as.factor(trt),dist='exp',data=dat.piecewise)

sWei1 <- survreg(s.weib0.5 ~ as.factor(trt),dist='weibull',data=dat.weib0.5)
sWei2 <- survreg(s.exp ~ as.factor(trt),dist='weibull',data=dat.exp)
sWei3 <- survreg(s.weib2 ~ as.factor(trt),dist='weibull',data=dat.weib2)
sWei4 <- survreg(s.weib5 ~ as.factor(trt),dist='weibull',data=dat.weib5)
sWei5 <- survreg(s.lognorm ~ as.factor(trt),dist='weibull',data=dat.lognorm)
sWei6 <- survreg(s.piecewise ~ as.factor(trt),dist='weibull',data=dat.piecewise)

sCox1 <- coxph(s.weib0.5 ~ trt,data=dat.weib0.5)
sCox2 <- coxph(s.exp ~ trt,data=dat.exp)
sCox3 <- coxph(s.weib2 ~ trt,data=dat.weib2)
sCox4 <- coxph(s.weib5 ~ trt,data=dat.weib5)
sCox5 <- coxph(s.lognorm ~ trt,data=dat.lognorm)
sCox6 <- coxph(s.piecewise~ trt,data=dat.piecewise)

```

```{r,warning=FALSE,fig.align='center',fig.height=13,fig.width=10,echo=FALSE}

#fKM <- survfit(s ~ trt,data=dat) # fit the data using survfit() method in black line as reference.
#baseline <- basehaz(sCox)

par(mfrow=c(6,3),pty="m")
par(mar = c(6, 6, 3, 0), oma = c(1, 1, 1, 1))
 
    plot(survfit(s.exp ~ trt,data=dat.exp),ylab = 'Exponential',main="Exponential",cex.axis=1.8,cex.lab=2,cex.main=2)
    lines(predict(sExp2, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    lines(predict(sExp2, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    plot(survfit(s.exp ~ trt,data=dat.exp),main = 'Weibull',cex.main = 2,cex.axis=1.8,cex.lab=2)
    lines(predict(sWei2, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    lines(predict(sWei2, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    plot(survfit(s.exp ~ trt,data=dat.exp),main = 'Cox',cex.main = 2,cex.axis=1.8,cex.lab=2)
    lines(survfit(sCox2,newdata=data.frame(trt=1),conf.int = F),col='green')
    lines(survfit(sCox2,newdata=data.frame(trt=0),conf.int = F),col='green')


    plot(survfit(s.weib0.5 ~ trt,data=dat.weib0.5),ylab = 'Weibull (0.5)',cex.axis=1.8,cex.lab=2)
    lines(predict(sExp1, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    lines(predict(sExp1, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    plot(survfit(s.weib0.5 ~ trt,data=dat.weib0.5),cex.axis=1.8,cex.lab=2)
    lines(predict(sWei1, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    lines(predict(sWei1, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    plot(survfit(s.weib0.5 ~ trt,data=dat.weib0.5),cex.axis=1.8,cex.lab=2)
    lines(survfit(sCox1,newdata=data.frame(trt=1),conf.int = F),col='green')
    lines(survfit(sCox1,newdata=data.frame(trt=0),conf.int = F),col='green')
    
    plot(survfit(s.weib2 ~ trt,data=dat.weib2),ylab = 'Weibull (2)',cex.axis=1.8,cex.lab=2)
    lines(predict(sExp3, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    lines(predict(sExp3, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    plot(survfit(s.weib2 ~ trt,data=dat.weib2),cex.axis=1.8)
    lines(predict(sWei3, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    lines(predict(sWei3, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    plot(survfit(s.weib2 ~ trt,data=dat.weib2),cex.axis=1.8)
    lines(survfit(sCox3,newdata=data.frame(trt=1),conf.int = F),col='green')
    lines(survfit(sCox3,newdata=data.frame(trt=0),conf.int = F),col='green')
   
    plot(survfit(s.weib5 ~ trt,data=dat.weib5),ylab = 'Weibull (5)',cex.axis=1.8,cex.lab=2)
    lines(predict(sExp4, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    lines(predict(sExp4, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    plot(survfit(s.weib5 ~ trt,data=dat.weib5),cex.axis=1.8)
    lines(predict(sWei4, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    lines(predict(sWei4, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    plot(survfit(s.weib5 ~ trt,data=dat.weib5),cex.axis=1.8)
    lines(survfit(sCox4,newdata=data.frame(trt=1),conf.int = F),col='green')
    lines(survfit(sCox4,newdata=data.frame(trt=0),conf.int = F),col='green')
    
    plot(survfit(s.lognorm ~ trt,data=dat.lognorm),ylab = 'Lognormal',cex.axis=1.8,cex.lab=2)
    lines(predict(sExp5, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    lines(predict(sExp5, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    plot(survfit(s.lognorm ~ trt,data=dat.lognorm),cex.axis=1.8)
    lines(predict(sWei5, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    lines(predict(sWei5, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    plot(survfit(s.lognorm ~ trt,data=dat.lognorm),cex.axis=1.8)
    lines(survfit(sCox5,newdata=data.frame(trt=1),conf.int = F),col='green')
    lines(survfit(sCox5,newdata=data.frame(trt=0),conf.int = F),col='green')
    
    plot(survfit(s.piecewise ~ trt,data=dat.piecewise),xlab = "t",ylab = 'Piecewise',cex.axis=1.8,cex.lab=2)
    lines(predict(sExp6, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    lines(predict(sExp6, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="blue")
    plot(survfit(s.piecewise ~ trt,data=dat.piecewise),xlab = "t",cex.axis=1.8,cex.lab=2)
    lines(predict(sWei6, newdata=list(trt=0),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    lines(predict(sWei6, newdata=list(trt=1),type="quantile",p=seq(.01,.99,by=.01)),seq(.99,.01,by=-.01),col="red")
    plot(survfit(s.piecewise ~ trt,data=dat.piecewise),xlab = "t",cex.axis=1.8,cex.lab=2)
    lines(survfit(sCox6,newdata=data.frame(trt=1),conf.int = F),col='green')
    lines(survfit(sCox6,newdata=data.frame(trt=0),conf.int = F),col='green')
```

\small Figure 2. Survival probabilities versus time for all models (columns) and baseline hazard functions (rows).

In Figure 2 above, we can observe the impact of baseline hazard misspecification when fitting a proportional hazards model. For example, the exponential model cannot accurately fit a baseline hazard distribution of Weibull($\gamma = 2,5$) due to concavity. For data simulated from the lognormal and piecewise baseline hazard functions, neither the exponential nor the Weibull models fit the survival data well. We also note that the Cox proportional hazards model has good fit across all six datasets, even when a simpler model would suffice. For instance, the Cox model appears to fit the simulated exponential data well, but the exponential model fits the data equally well. Thus, it may be more advantageous to utilize the exponential model in this case to increase parsimony and interpretability, and minimize model complexity.

In Table 2 below, we calculated the MSE of the treatment effect estimates from the three models and six baseline hazard functions. The Weibull model had the lowest MSE for data simulated from a Weibull hazard curve with $\gamma = 2,5$. The Cox proportional hazard model achieves lowest MSE among data simulated from exponential, Weibull with $\gamma = 0.5$, lognormal, and piecewise hazard curves. While the exponential model by MSE never performed best, its performance was nearly identical to the Cox model for data simulated from an exponential distribution. Similarly, for data from a Weibull with $\gamma = 0.5$, the Cox performed only slightly better. 
  
\bigskip



```{r, include=FALSE}
#import all simulation results
path_to_gamma0.5= "./results_gamma0.5.csv"
path_to_gamma1= "./results_gamma1.csv"
path_to_gamma2= "./results_gamma2.csv"
path_to_gamma5= "./results_gamma5.csv"
path_to_logn= "./results_lognormal.csv"
path_to_piecewise = "./results_piecewise.csv"
result_0.5 = read_csv(file = path_to_gamma0.5)
result_1 = read_csv(file = path_to_gamma1)
result_2 = read_csv(file = path_to_gamma2)
result_5 = read_csv(file = path_to_gamma5)
result_ln = read_csv(file = path_to_logn)
result_pw = read_csv(file = path_to_piecewise) # Load the sets
```
  
```{r, echo=FALSE}
MSE = function(beta, n=1000) {
  return(sum((-0.5 - beta)^2)/n)
}

MSE_table = tibble(
  Model = c("Exponential", "Weibull", "Cox"),
  Exponential = round(c(MSE(result_1$exp_beta), MSE(result_1$weibull_beta), MSE(result_1$cox_beta)), 4),
  "Weibull(0.5)" = round(c(MSE(result_0.5$exp_beta), MSE(result_0.5$weibull_beta), MSE(result_0.5$cox_beta)),4),
  "Weibull(2)" = round(c(MSE(result_2$exp_beta), MSE(result_2$weibull_beta), MSE(result_2$cox_beta)), 4),
  "Weibull(5)" = round(c(MSE(result_5$exp_beta), MSE(result_5$weibull_beta), MSE(result_5$cox_beta)),4),
  Lognormal = round(c(MSE(result_ln$exp_beta), MSE(result_ln$weibull_beta), MSE(result_ln$cox_beta)),4),
  Piecewise = round(c(MSE(result_pw$exp_beta), MSE(result_pw$weibull_beta), MSE(result_pw$cox_beta)),4)
) %>% # MSE of 1000 beta
  knitr::kable()
MSE_table
```


\small Table 2. MSEs from three models using 1000 simulations. Weibull base hazard functions are denoted as Weibull($\gamma$).


\bigskip



```{r, echo=FALSE}
mean_sd_beta = tibble(
  Model = c("Exponential", "Weibull", "Cox"),
  Exponential = c("-0.523 (0.387)", "-0.524 (0.388)", "-0.520 (0.386)"),
  "Weibull(0.5)" = c("-0.547 (0.573)", "-0.533 (0.559)", "-0.529 (0.556)"),
  "Weibull(2)"= c("-0.350 (0.155)", "-0.504 (0.221)", "-0.501 (0.221)"),
  "Weibull(5)" = c("-0.101 (0.045)", "-0.509 (0.209)", "-0.507 (0.215)"),
  Lognormal = c("-0.248 (0.097)", "-0.656 (0.263)", "-0.510 (0.205)"),
  Piecewise = c("-0.576 (0.224)", "-0.528 (0.214)", "-0.510 (0.205)")
) %>%
  knitr::kable() # mean of 1000 beta
mean_sd_beta
```


\small Table 3. Mean (SD) of $\hat{\beta}$ from three models using 1000 simulations. Weibull base hazard functions are denoted as Weibull($\gamma$).


\bigskip


In Table 3 above, we see the breakdown of the average estimated treatment effect for each model and baseline hazard function. As the true treatment effect was $\beta = -0.5$, we see that the mean estimated treatment effect across all simulations was closest to this value for the Cox model, regardless of the baseline hazard function. We can see that in the case of the data simulated from the Weibull($\gamma = 5$) distribution and the lognormal distribution, fitting an exponential model introduces large bias in the estimation of the treatment effect, with mean estimates of -0.101 and -0.248, respectively. As far as the standard deviation of this estimates across simulations, there is little difference between correclty specified distribution models and the Cox model. Interestingly, in the cases where the exponential model has been misspecified the variation across samples of the estimates is small. This might explain why in some cases the exponential model outperforms the Weibull in terms of MSE, even when fit on Weibull simulated data, such as in the case of Weibull($\gamma = 2$). 



# Conclusions

By comparing the Mean square error(MSE) and mean of $\beta$ derived from three models in different simulations, we found that misspecifying the baseline hazard function can lead to significant differences between actual value of $\beta$ and the truth ($\beta = -0.5$). 

For example, the exponential and Weibull models obtained high MSEs due to biased means of $\beta$ in data simulated by the lognormal or piecewise distribution. We further confirmed the deviated estimation through of survival curves in Figure 2, where we see the Weibull and exponential model can not provide the a fitted curve to match the observed. For these simulations, the Cox model provided small MSE values, and the fitted curve of Cox PH model was quite consistent with the observed data. Thus we demonstrated that Cox model can estimate the treatment effect with high accuracy and precision compared to a misspecified distribution, as expected. 

On the other hand, in the case of the impact of fitting too complicated a model when an simpler model is sufficient, we found that there were minimal consequences of the more complex models, in terms of MSE. For example, when fitting models on data from an exponential distribution, all three had very similar levels of MSE, mean predicted value of $\beta$, and standard deviation. There was no case where the Cox model performed significantly worse than other models, in terms of MSE, and in every case it outperformed other models in terms of bias. This confirms the finding that the Cox proportional hazard model is semi-parametrically efficient, as even when a simpler model would suffice it still performs well. The Cox model's good performance in these cases is further demonstrated in Figure 2, where we see it follows the observed data closely, regardless of the underlying hazard curve the data was sampled from.


# Contributions

Charly Fowler worked on simulation functions, performed piecewise simulation, plotted baseline hazard curves, and created datasets of results.
Hanfei Qi worked on formatting simulation functions and editing plotting functions.
Robert Tumasian III worked on editing simulation functions and plots, performing lognormal simulation, and creating datasets of results.
Haoyang Yi worked on creating plotting functions and editing simulation functions.
All members contributed equally to this project.

# References 

Andersen, Per Kragh, and Richard D. Gill. "Cox's regression model for counting processes: a large sample study." The annals of statistics (1982): 1100-1120.

Brilleman, Samuel, Rory Wolfe, Margarita Moreno-Betancur, & Michael J. Crowther. "Simulating Survival Data Using the simsurv R Package." \textit{Journal of Statistical Software} [Online], 97.3 (2021): 1 - 27. Web. 23 Feb. 2021